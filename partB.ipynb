{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2e0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch \n",
    "!pip install torchvision\n",
    "!pip install torchsummary\n",
    "!pip install wandb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51001a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import os\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224  # Resize to ImageNet standard\n",
    "# IMAGE_SIZE = 299\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_dir = os.path.join(\"nature_12K\", \"inaturalist_12K\")\n",
    "full_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)\n",
    "best_model_path = \"best_models\"\n",
    "os.makedirs(best_model_path, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38879f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your train_dir and val_dir properly\n",
    "\n",
    "train_dir = os.path.join(data_dir, \"train\")  # replace with actual path\n",
    "# val_dir = os.path.join(data_dir, \"train\")  # optional if splitting from train_dir\n",
    "\n",
    "\n",
    "# === get_data_loaders === #\n",
    "def get_data_loaders(config, train_dir=train_dir):\n",
    "    BATCH_SIZE = config.get(\"batch_size\", 64)\n",
    "    IMAGE_SIZE = 224\n",
    "    # IMAGE_SIZE = 299\n",
    "\n",
    "    if config.get(\"augment\", False):\n",
    "        print(\"Applying full data augmentation\")\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation(20),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.02),\n",
    "            transforms.RandomGrayscale(p=0.1),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "        ])\n",
    "    else:\n",
    "        print(\"Minimal preprocessing, no augmentation\")\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "        ])\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "    # Load dataset\n",
    "    full_dataset = datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
    "    targets = np.array(full_dataset.targets)\n",
    "\n",
    "    # Stratified split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    train_idx, val_idx = next(sss.split(np.zeros(len(targets)), targets))\n",
    "\n",
    "    train_dataset = Subset(full_dataset, train_idx)\n",
    "    val_dataset = Subset(datasets.ImageFolder(root=train_dir, transform=transform_val), val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    print(f\"Total images: {len(full_dataset)}\")\n",
    "    print(f\"Training set: {len(train_dataset)} images\")\n",
    "    print(f\"Validation set: {len(val_dataset)} images\")\n",
    "    print(f\"Number of classes: {len(full_dataset.classes)}\")\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d81f04",
   "metadata": {},
   "source": [
    "Train one epoch and eval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e420004",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, epoch):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for images, labels in tqdm(loader, desc=f\"Train Epoch {epoch}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Comment the following lines if using a model with auxiliary outputs (like InceptionV3)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Uncomment the following lines if using a model with auxiliary outputs (like InceptionV3)\n",
    "        # outputs, aux_output = model(images)\n",
    "        # loss = criterion(outputs, labels) + 0.4 * criterion(aux_output, labels)\n",
    " \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    wandb.log({\"train/loss\": epoch_loss, \"train/acc\": epoch_acc, \"epoch\": epoch})\n",
    "    print(f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}\")\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=f\"Eval Epoch {epoch}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    epoch_loss = val_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    wandb.log({\"val/loss\": epoch_loss, \"val/acc\": epoch_acc, \"epoch\": epoch})\n",
    "    print(f\"Validation Loss: {epoch_loss:.4f}, Validation Acc: {epoch_acc:.4f}\")\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f8f959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROJECT_NAME = \"da24m029-da6401-assignment2\"  # Replace with your project name\n",
    "ENTITY_NAME = \"da24m029-indian-institute-of-technology-madras\"  # Replace with your entity name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# === Configurable ===\n",
    "BACKBONE = \"resnet50\"  # Options: 'resnet50', 'vgg16', 'efficientnet_v2_s', 'inception_v3', 'vit_b_16'\n",
    "FREEZE_STRATEGY = \"partial_percent\"  # Options: 'last_only', 'partial_k', 'partial_percent'\n",
    "K = 10  # Used if FREEZE_STRATEGY == 'partial_k'\n",
    "PERCENT = 0.7  # Used if FREEZE_STRATEGY == 'partial_percent'\n",
    "\n",
    "def get_pretrained_model(backbone_name, num_classes):\n",
    "    if backbone_name == \"resnet50\":\n",
    "        model = models.resnet50(weights='DEFAULT')\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "        feature_layers = list(model.children())[:-1]\n",
    "    elif backbone_name == \"vgg16\":\n",
    "        model = models.vgg16(weights='DEFAULT')\n",
    "        in_features = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(in_features, num_classes)\n",
    "        feature_layers = list(model.features)\n",
    "    elif backbone_name == \"efficientnet_v2_s\":\n",
    "        model = models.efficientnet_v2_s(weights='DEFAULT')\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "        feature_layers = list(model.features)\n",
    "    elif backbone_name == \"inception_v3\":\n",
    "        model = models.inception_v3(weights='DEFAULT', aux_logits=True)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "        feature_layers = list(model.children())[:-1]\n",
    "    elif backbone_name == \"vit_b_16\":\n",
    "        model = models.vit_b_16(weights='DEFAULT')\n",
    "        in_features = model.heads.head.in_features\n",
    "        model.heads.head = nn.Linear(in_features, num_classes)\n",
    "        feature_layers = list(model.children())[:-1]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported backbone\")\n",
    "\n",
    "    return model#, feature_layers\n",
    "\n",
    "# def apply_freezing_strategy(model, feature_layers, strategy, k=None, percent=None):\n",
    "def apply_freezing_strategy(model, strategy, k=None, percent=None):\n",
    "    all_params = list(model.parameters())\n",
    "\n",
    "    if strategy == \"last_only\":\n",
    "        for param in all_params:\n",
    "            param.requires_grad = False\n",
    "        # Unfreeze only classifier\n",
    "        for param in model.parameters():\n",
    "            if param.ndim > 1 and param.requires_grad == False:\n",
    "                continue\n",
    "            param.requires_grad = True\n",
    "\n",
    "    elif strategy == \"partial_k\":\n",
    "        for idx, param in enumerate(all_params):\n",
    "            param.requires_grad = idx >= k\n",
    "\n",
    "    elif strategy == \"partial_percent\":\n",
    "        freeze_until = int(len(all_params) * percent)\n",
    "        for idx, param in enumerate(all_params):\n",
    "            param.requires_grad = idx >= freeze_until\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown freezing strategy\")\n",
    "\n",
    "def finetune_model(backbone=BACKBONE, strategy=FREEZE_STRATEGY, k=K, percent=PERCENT, num_classes=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # model, feature_layers = get_pretrained_model(backbone, num_classes)\n",
    "    model = get_pretrained_model(backbone, num_classes)\n",
    "\n",
    "    # Apply freezing\n",
    "    # apply_freezing_strategy(model, feature_layers, strategy, k, percent)\n",
    "    apply_freezing_strategy(model, strategy, k, percent)\n",
    "\n",
    "    model.to(device)\n",
    "    print(f\"Model: {backbone}, Strategy: {strategy} â†’ Ready for training.\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aa940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_finetune_training(\n",
    "    backbone=\"resnet50\", strategy=\"last_only\", num_epochs=10, batch_size=32,\n",
    "    k=10, percent=0.7, num_classes=10\n",
    "):\n",
    "    # wandb init\n",
    "    wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        entity=ENTITY_NAME,\n",
    "        config={\n",
    "            \"backbone\": backbone,\n",
    "            \"strategy\": strategy,\n",
    "            \"epochs\": num_epochs,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"freeze_k\": k,\n",
    "            \"freeze_percent\": percent,\n",
    "            # \"augment\": False\n",
    "        }\n",
    "    )\n",
    "    wandb.run.name = f\"backbone={backbone}, strategy={strategy}, epochs={num_epochs}, batch_size={batch_size}, freeze_k={k}, freeze_percent={percent}\"\n",
    "    wandb.run.save()\n",
    "    \n",
    "    config = wandb.config\n",
    "\n",
    "    train_loader, val_loader = get_data_loaders(config)\n",
    "\n",
    "    # Load model\n",
    "    model = finetune_model(backbone=config.backbone,\n",
    "                           strategy=config.strategy,\n",
    "                           k=config.freeze_k,\n",
    "                           percent=config.freeze_percent,\n",
    "                           num_classes=num_classes)\n",
    "\n",
    "    # Optimizer and criterion\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_one_epoch(model, train_loader, optimizer, criterion, device, epoch)\n",
    "        evaluate(model, val_loader, criterion, device, epoch)\n",
    "\n",
    "    torch.save(model, os.path.join(best_model_path, \"partB.pth\"))\n",
    "    wandb.save(\"best_model_B.pth\")\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e3cf5",
   "metadata": {},
   "source": [
    "FineTune Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018f6993",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = run_finetune_training(\n",
    "                    backbone=\"resnet50\",\n",
    "                    strategy=\"last_only\",\n",
    "                    percent=0.6,\n",
    "                    num_epochs=100,\n",
    "                    num_classes=10,\n",
    "                    batch_size=64,\n",
    "                    k=10,\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c535c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "# IMAGE_SIZE = 299\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),  # match training image size\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize([0.5], [0.5]),  # match training normalization\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(os.path.join(data_dir,'test'), transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "147c13ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final Test Accuracy: 0.6090\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "finetuned_model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = finetuned_model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "# Print it\n",
    "print(f\" Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Log to wandb (if active)\n",
    "if wandb.run is not None:\n",
    "    wandb.log({\"test_accuracy\": test_accuracy})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c926b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
