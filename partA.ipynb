{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b2f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch \n",
    "!pip install torchvision\n",
    "!pip install torchsummary\n",
    "!pip install wandb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e047479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import wandb\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90064d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: nature_12K\\inaturalist_12K\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join('nature_12K', 'inaturalist_12K')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "best_model_path = \"best_models\"\n",
    "os.makedirs(best_model_path, exist_ok=True)\n",
    "\n",
    "print(\"Data directory:\", data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb1ecf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data_loaders(config):\n",
    "    # Constants\n",
    "    BATCH_SIZE = config.get(\"batch_size\", 64)\n",
    "    IMAGE_SIZE = 224\n",
    "    \n",
    "\n",
    "    # Augmentation logic\n",
    "    if config.get(\"augment\", False):\n",
    "        print(\"Applying full data augmentation\")\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation(20),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.02),\n",
    "            transforms.RandomGrayscale(p=0.1),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5]),\n",
    "        ])\n",
    "    else:\n",
    "        print(\"Minimal preprocessing, no augmentation\")\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5]),\n",
    "        ])\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ])\n",
    "\n",
    "    # Load full training dataset\n",
    "    full_dataset = datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
    "    targets = np.array(full_dataset.targets)\n",
    "\n",
    "    # Stratified split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    train_idx, val_idx = next(sss.split(np.zeros(len(targets)), targets))\n",
    "\n",
    "    # Subsets with respective transforms\n",
    "    train_dataset = Subset(full_dataset, train_idx)\n",
    "    val_dataset = Subset(datasets.ImageFolder(root=train_dir, transform=transform_val), val_idx)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    # Info\n",
    "    print(f\"Total images: {len(full_dataset)}\")\n",
    "    print(f\"Training set: {len(train_dataset)} images\")\n",
    "    print(f\"Validation set: {len(val_dataset)} images\")\n",
    "    print(f\"Number of classes: {len(full_dataset.classes)}\")\n",
    "\n",
    "    return train_loader, val_loader #, len(full_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b85588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleCNN(nn.Module):\n",
    "    def __init__(self, num_filters, activation_fn, kernel_size, dense_neurons, num_classes=1010, dropout_rate=0.2, batch_norm=False):\n",
    "        super().__init__()\n",
    "\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'gelu': nn.GELU(),\n",
    "            'silu': nn.SiLU(),\n",
    "            'mish': nn.Mish()\n",
    "        }[activation_fn]\n",
    "\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "\n",
    "        for nf in num_filters:\n",
    "            layers.append(nn.Conv2d(in_channels, nf, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm2d(nf))\n",
    "            layers.append(act_fn)\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2))\n",
    "            in_channels = nf\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.dense = nn.Linear(num_filters[-1] * 7 * 7, dense_neurons)\n",
    "        self.output = nn.Linear(dense_neurons, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.output(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a2746ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Computations: 197,953,010\n",
      "Total Parameters: 5,642,930\n"
     ]
    }
   ],
   "source": [
    "def compute_model_stats(m, k, n, input_size=(224, 224), num_layers=555, num_classes=1010):\n",
    "    H, W = input_size\n",
    "    computations = 0\n",
    "    params = 0\n",
    "    in_channels = 3\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        # Computations per conv: H*W * (in_channels * k^2)\n",
    "        computations += H * W * (in_channels * k * k) * m\n",
    "        # Parameters per conv: m * (in_channels * k^2 + 1 bias)\n",
    "        params += m * (in_channels * k * k + 1)\n",
    "        in_channels = m\n",
    "        H, W = H // 2, W // 2  # Due to MaxPooling\n",
    "\n",
    "    flattened = in_channels * H * W\n",
    "    params += flattened * n + n  # Dense layer\n",
    "    params += n * num_classes + num_classes  # Output layer\n",
    "    computations += flattened * n + n + n * num_classes + num_classes\n",
    "\n",
    "    return computations, params\n",
    "\n",
    "# Example usage\n",
    "m, k, n = 32, 3, 512\n",
    "comp, param = compute_model_stats(m, k, n)\n",
    "print(f\"Total Computations: {comp:,}\")\n",
    "print(f\"Total Parameters: {param:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb7eafea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for images, labels in tqdm(loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return val_loss / total, correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b3c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"da24m029-da6401-assignment2\"  # Replace with your project name\n",
    "ENTITY_NAME = \"da24m029-indian-institute-of-technology-madras\"  # Replace with your entity name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3523ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_train():\n",
    "    wandb.init(project=PROJECT_NAME, entity=ENTITY_NAME)\n",
    "    config = wandb.config\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Compute num_filters based on filter_organization\n",
    "    num_layers = 5\n",
    "    if config.filter_organization == \"same\":\n",
    "        filters = [config.filters_base] * num_layers\n",
    "    elif config.filter_organization == \"double\":\n",
    "        filters = [config.filters_base * (2 ** i) for i in range(num_layers)]\n",
    "    elif config.filter_organization == \"half\":\n",
    "        # filters = [max(config.filters_base // (2 ** i), 1) for i in range(num_layers)]\n",
    "        filters = [config.filters_base * (2 ** i) for i in range(num_layers)]\n",
    "        filters = filters[::-1]  # Reverse the order\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown filter organization: {config.filter_organization}\")\n",
    "\n",
    "    wandb.run.name = (\n",
    "        f\"fbase_{config.filters_base}_\"\n",
    "        f\"forg_{config.filter_organization}_\"\n",
    "        f\"act_{config.activation}_\"\n",
    "        f\"k_{config.kernel_size}_\"\n",
    "        f\"drop_{config.dropout}_\"\n",
    "        f\"bn_{config.batch_norm}_\"\n",
    "        f\"lr_{config.lr:.5f}_\"\n",
    "        f\"aug_{config.augment}_\"\n",
    "        f\"ep_{config.epochs}_\"\n",
    "        f\"bs_{config.batch_size}_\"\n",
    "        f\"n_{config.dense_neurons}\"\n",
    "    )\n",
    "    wandb.run.save()\n",
    "\n",
    "    # DataLoader\n",
    "    train_loader, val_loader = get_data_loaders(\n",
    "        {\n",
    "        \"batch_size\":config.batch_size,\n",
    "        \"augment\":config.augment\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    model = FlexibleCNN(\n",
    "        num_filters=filters,\n",
    "        activation_fn=config.activation,\n",
    "        kernel_size=config.kernel_size,\n",
    "        dense_neurons=config.dense_neurons,\n",
    "        dropout_rate=config.dropout,\n",
    "        batch_norm=config.batch_norm\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_acc\n",
    "        })\n",
    "        print(f\"Epoch {epoch + 1}/{config.epochs} - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} - \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            # torch.save(model.state_dict(), os.path.join(best_model_path, \"partA.pth\"))\n",
    "            torch.save(model, os.path.join(best_model_path, \"partA.pth\"))\n",
    "            wandb.save(\"best_model_A.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d79a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"filters_base\": {\"values\": [3, 8, 16, 32, 64]},\n",
    "        \"filter_organization\": {\"values\": [\"same\", \"double\", \"half\"]},\n",
    "        \"activation\": {\"values\": [\"relu\", \"gelu\", \"silu\", \"mish\"]},\n",
    "        \"kernel_size\": {\"values\": [3, 5]},\n",
    "        \"dense_neurons\": {\"values\": [256, 512]},\n",
    "        \"batch_norm\": {\"values\": [True, False]},\n",
    "        \"dropout\": {\"values\": [0.2, 0.3]},\n",
    "        \"lr\": {\"distribution\": \"uniform\", \"min\": 0.0001, \"max\": 0.01},\n",
    "        \"batch_size\": {\"values\": [32, 64]},\n",
    "        \"augment\": {\"values\": [True, False]},\n",
    "        \"epochs\": {\"values\": [5, 10, 15]}\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, project=PROJECT_NAME, entity=ENTITY_NAME)\n",
    "wandb.agent(sweep_id, function=sweep_train, count=60)  # Adjust count as needed\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fd043da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = torch.load(os.path.join(best_model_path, \"partA.pth\"))\n",
    "torch.serialization.add_safe_globals([FlexibleCNN])\n",
    "best_model = torch.load(os.path.join(best_model_path, \"partA.pth\"), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29dcacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal preprocessing, no augmentation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 9999\n",
      "Training set: 7999 images\n",
      "Validation set: 2000 images\n",
      "Number of classes: 10\n",
      "best_model.pth not found or incompatible. Training the model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Reuse best known hyperparameters from your sweep\n",
    "best_config = {\n",
    "    \"num_filters\": [8, 16, 32, 64, 128],     # Filter sizes in each conv layer\n",
    "    \"kernel_size\": 3,                           # Convolution kernel size\n",
    "    \"activation\": \"silu\",                       # Activation function\n",
    "    \"use_batchnorm\": True,                      # BatchNorm after conv?\n",
    "    \"dropout\": 0.3,                             # Dropout rate\n",
    "    \"dense_neurons\": 256,                       # FC layer size before classifier\n",
    "    \"num_classes\": 10,                        # Number of output classes\n",
    "    \"lr\": 0.00107,                                 # Learning rate\n",
    "    \"batch_size\": 64,                           # Just for tracking, if dynamic\n",
    "    \"augment\": False,                            # If data augmentation is used\n",
    "    \"epochs\": 10                                # Number of training epochs\n",
    "}\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate model\n",
    "# Instantiate model\n",
    "best_model = FlexibleCNN(\n",
    "    num_filters=best_config[\"num_filters\"],\n",
    "    kernel_size=best_config[\"kernel_size\"],\n",
    "    activation_fn=best_config[\"activation\"],          \n",
    "    batch_norm=best_config[\"use_batchnorm\"],          \n",
    "    dropout_rate=best_config[\"dropout\"],              \n",
    "    dense_neurons=best_config[\"dense_neurons\"],\n",
    "    num_classes=best_config[\"num_classes\"]\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "train_loader, val_loader = get_data_loaders(\n",
    "        {\n",
    "        \"batch_size\": best_config[\"batch_size\"],\n",
    "        \"augment\": best_config[\"augment\"]\n",
    "\n",
    "        }\n",
    "    )\n",
    "# Load or Train Model\n",
    "try:\n",
    "    # best_model = torch.load(os.path.join(best_model_path, \"partA.pth\"))\n",
    "    torch.serialization.add_safe_globals([FlexibleCNN])\n",
    "    best_model = torch.load(os.path.join(best_model_path, \"partA.pth\"), weights_only=False)\n",
    "    print(\"Loaded best_model.pth\")\n",
    "except (FileNotFoundError, RuntimeError) as e:\n",
    "    print(\"best_model.pth not found or incompatible. Training the model...\")\n",
    "\n",
    "    # Initialize wandb\n",
    "    wandb.init(project=PROJECT_NAME, entity=ENTITY_NAME, name=\"retrained_best_model\", config=best_config)\n",
    "\n",
    "    # Optimizer & Loss\n",
    "    optimizer = torch.optim.Adam(best_model.parameters(), lr=best_config[\"lr\"])\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(best_config[\"epochs\"]):\n",
    "        train_loss, train_acc = train_one_epoch(best_model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate(best_model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Log metrics to wandb\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_acc\n",
    "        })\n",
    "\n",
    "    torch.save(best_model, os.path.join(best_model_path, \"partA.pth\"))\n",
    "    \n",
    "    print(\"Saved new best_model.pth\")\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "# Set to evaluation mode for testing/inference\n",
    "best_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9484e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # match training image size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),  # match training normalization\n",
    "])\n",
    "\n",
    "\n",
    "test_dataset = datasets.ImageFolder(os.path.join(data_dir,'val'), transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d99a66ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:31<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final Test Accuracy: 0.2290\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "# Print it\n",
    "print(f\" Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Log to wandb (if active)\n",
    "if wandb.run is not None:\n",
    "    wandb.log({\"test_accuracy\": test_accuracy})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364aa80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly pick 30 test images\n",
    "indices = random.sample(range(len(test_dataset)), 30)\n",
    "fig, axes = plt.subplots(10, 3, figsize=(12, 30))\n",
    "\n",
    "for ax, idx in zip(axes.flatten(), indices):\n",
    "    img, true_label = test_dataset[idx]\n",
    "    model_input = img.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = best_model(model_input).argmax().item()\n",
    "\n",
    "    # De-normalize for visualization\n",
    "    img_np = img.permute(1, 2, 0).numpy()\n",
    "    img_np = np.clip((img_np * 0.5) + 0.5, 0, 1)\n",
    "\n",
    "    ax.imshow(img_np)\n",
    "    ax.set_title(f\"Pred: {test_dataset.classes[pred]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_predictions_grid.png\")  # Save the plot\n",
    "\n",
    "# Log to wandb\n",
    "if wandb.run is not None:\n",
    "    wandb.log({\n",
    "        \"Test Prediction Grid\": wandb.Image(\"test_predictions_grid.png\")\n",
    "    })\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af7ed9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_params_and_ops(m=16, k=3, n=512, input_size=224, blocks=555, num_classes=101010):\n",
    "    # After each maxpool, size halves: 224 -> 112 -> 56 ...\n",
    "    size = input_size\n",
    "    ops_total = 0\n",
    "    for i in range(blocks):\n",
    "        ops = (k * k * m * m) * (size * size)  # assuming in_channels = out_channels = m\n",
    "        ops_total += ops\n",
    "        size = size // 2  # after maxpool\n",
    "\n",
    "    # Final feature map size\n",
    "    conv_out_size = size\n",
    "    conv_features = m * (conv_out_size ** 2)\n",
    "\n",
    "    # Dense ops and params\n",
    "    dense_ops = conv_features * n\n",
    "    out_ops = n * num_classes\n",
    "\n",
    "    total_ops = ops_total + dense_ops + out_ops\n",
    "\n",
    "    # Params: conv + dense\n",
    "    conv_params = blocks * (k * k * m * m + m)  # +bias\n",
    "    dense_params = conv_features * n + n + n * num_classes + num_classes\n",
    "\n",
    "    return {\n",
    "        \"conv_ops\": ops_total,\n",
    "        \"dense_ops\": dense_ops + out_ops,\n",
    "        \"total_ops\": total_ops,\n",
    "        \"total_params\": conv_params + dense_params\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45daf9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv Ops: 154,126,080\n",
      "Dense Ops: 51,717,120\n",
      "Total Ops: 205,843,200\n",
      "Total Params: 53,106,242\n"
     ]
    }
   ],
   "source": [
    "result = compute_params_and_ops(m=16, k=3, n=512, input_size=224, blocks=555, num_classes=101010)\n",
    "print(\"Conv Ops:\", f\"{result['conv_ops']:,}\")\n",
    "print(\"Dense Ops:\", f\"{result['dense_ops']:,}\")\n",
    "print(\"Total Ops:\", f\"{result['total_ops']:,}\")\n",
    "print(\"Total Params:\", f\"{result['total_params']:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335315e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
